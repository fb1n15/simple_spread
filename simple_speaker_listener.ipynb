{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babc9d11-2435-4e60-9a81-34dd5bac6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.mpe import simple_speaker_listener_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0914fc1d-59bc-4e22-8526-af0111485e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simple_speaker_listener_v4.env(max_cycles=25, continuous_actions=False, render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b066ffed-ec75-4593-8551-ae62053c8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9dc28b-2fb7-4e32-b0af-bdbb595bd1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speaker_0', 'listener_0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a89ae33-76a5-4685-9c5e-29cc8e485f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker_0 Box(-inf, inf, (3,), float32)\n",
      "listener_0 Box(-inf, inf, (11,), float32)\n"
     ]
    }
   ],
   "source": [
    "for agent in env.agents:\n",
    "    print(agent, env.observation_space(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd7e04a-c2a8-4ed2-8f5f-e3183a61f7e7",
   "metadata": {},
   "source": [
    "## Observation Space\n",
    "**Speaker's Observation Space (`Box(-inf, inf, (3,), float32)`):**\n",
    "\n",
    "The speaker's observation is a 3-dimensional vector comprising:\n",
    "\n",
    "1. **Goal Color**: A 3-element array representing the RGB color of the target landmark. This information is crucial for the speaker to identify and communicate the correct landmark to the listener.\n",
    "\n",
    "**Listener's Observation Space (`Box(-inf, inf, (11,), float32)`):**\n",
    "\n",
    "The listener's observation is an 11-dimensional vector consisting of:\n",
    "\n",
    "1. **Self Velocity**: A 2-element array indicating the listener's current velocity in the environment.\n",
    "2. **Relative Positions of All Landmarks**: Three 2-element arrays (totaling 6 elements) representing the positions of each landmark relative to the listener's current position.\n",
    "3. **Communication from Speaker**: A 3-element array containing the message sent by the speaker, which typically encodes the target landmark's color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b71870d-c8f1-4624-8f46-59e95f3e49f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker_0 Discrete(3)\n",
      "listener_0 Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "for agent in env.agents:\n",
    "    print(agent, env.action_space(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cea33c-9958-4024-9ae5-89a8e5c04302",
   "metadata": {},
   "source": [
    "## Action Space\n",
    "In the PettingZoo environment `simple_speaker_listener_v4`, the action spaces for the agents are defined as follows:\n",
    "\n",
    "**Speaker's Action Space (`Discrete(3)`):**\n",
    "\n",
    "The speaker has 10 discrete actions, each corresponding to a unique message it can send to the listener. These actions are:\n",
    "\n",
    "- `say_0`\n",
    "- `say_1`\n",
    "- `say_2`\n",
    "\n",
    "Each action transmits a specific message to the listener, aiding in identifying the target landmark.\n",
    "\n",
    "**Listener's Action Space (`Discrete(5)`):**\n",
    "\n",
    "The listener has 5 discrete actions, dictating its movement within the environment:\n",
    "\n",
    "- `no_action`: Remain stationary.\n",
    "- `move_left`: Move left.\n",
    "- `move_right`: Move right.\n",
    "- `move_down`: Move down.\n",
    "- `move_up`: Move up.\n",
    "\n",
    "These actions enable the listener to navigate towards the target landmark based on the speaker's messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7ee57e-d670-4489-879d-bd1aaa398cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65, 0.15, 0.15], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation, reward, termination, trunc, info = env.last()\n",
    "observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1c0d4-1ac5-4832-9929-eed4f24bfa2c",
   "metadata": {},
   "source": [
    "## Speaker's Observation:\n",
    "In the `simple_speaker_listener_v4` environment, the speaker's observation is represented by the `goal_color`, which is a 3-element array corresponding to the RGB (Red, Green, Blue) values of the target landmark's colour. ([GitHub](https://github.com/Farama-Foundation/PettingZoo/blob/master/pettingzoo/mpe/simple_speaker_listener/simple_speaker_listener.py?utm_source=chatgpt.com))\n",
    "\n",
    "The array `[0.65, 0.15, 0.15]` signifies:\n",
    "\n",
    "- **Red component**: 0.65\n",
    "- **Green component**: 0.15\n",
    "- **Blue component**: 0.15\n",
    "\n",
    "This indicates that the target landmark is primarily red in colour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcda9c52-c959-4fd1-a43c-11280808fb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        , -0.05328575,  0.4192263 , -0.62044495,\n",
       "        0.13264017, -1.110282  ,  1.009471  ,  0.        ,  0.        ,\n",
       "        0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.agent_selection = env.agents[1]\n",
    "observation, reward, termination, trunc, info = env.last()\n",
    "observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd88484-5a18-4f06-8f43-ae00551e4891",
   "metadata": {},
   "source": [
    "## Listener's observation\n",
    "In the `simple_speaker_listener_v4` environment, the listener's observation is an array comprising:\n",
    "\n",
    "- **Self Velocity**: The listener's own velocity components.\n",
    "- **Relative Positions of All Landmarks**: The positions of all landmarks relative to the listener's current position.\n",
    "- **Communication from the Speaker**: The message or communication received from the speaker agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d2d06f4-1a80-41f2-862d-c9720c781739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n",
      "Agent index: listener_0\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment to its initial state\n",
    "env.reset()\n",
    "\n",
    "# Iterate over each agent in the environment\n",
    "for agent in env.agent_iter():\n",
    "    # Print the current agent's identifier\n",
    "    print(f\"Agent index: {agent}\")\n",
    "    \n",
    "    # Retrieve the last observation, reward, termination, truncation, and info for the current agent\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "    \n",
    "    # Initialize the action variable\n",
    "    action = None\n",
    "    \n",
    "    # Determine the action to take if the agent is neither terminated nor truncated\n",
    "    if not (termination or truncation):\n",
    "        # Assign a default action (e.g., action 0) or implement a policy to select an action\n",
    "        action = 0  # Replace with a policy-based action selection if available\n",
    "    \n",
    "    # Execute the chosen action in the environment\n",
    "    env.step(action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039161ea-803e-4040-8ce8-91592d9c10b9",
   "metadata": {},
   "source": [
    "## why only listener here?\n",
    "The agent_iter() function iterates over agents that are expected to take actions. Since the speaker cannot move and its only action is to send a fixed message, it doesn't require iterative action decisions during the environment's execution. Therefore, agent_iter() primarily yields the listener, who needs to decide on movement actions based on the received communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47384422-d465-401b-9b83-36449f634f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeakerPolicy:\n",
    "    \"\"\"Policy class for the Speaker agent in the simple_speaker_listener_v4 environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, world):\n",
    "        \"\"\"\n",
    "        Initializes the SpeakerPolicy with a memory mapping of landmark colors to their indices.\n",
    "        \n",
    "        Args:\n",
    "            world: The environment world object containing landmarks.\n",
    "        \"\"\"\n",
    "        # Create a dictionary mapping each landmark's color (as a string) to its index\n",
    "        self._goal_memory = {\n",
    "            str(land.color): idx\n",
    "            for idx, land in enumerate(world.landmarks)\n",
    "        }\n",
    "    \n",
    "    def predict(self, observation):\n",
    "        \"\"\"\n",
    "        Predicts the optimal action (landmark index) based on the observed goal color.\n",
    "        \n",
    "        Args:\n",
    "            observation: The observed goal color.\n",
    "        \n",
    "        Returns:\n",
    "            The index of the landmark corresponding to the observed goal color.\n",
    "        \"\"\"\n",
    "        # Convert the observation (goal color) to a string to match the keys in _goal_memory\n",
    "        goal_id = str(observation)\n",
    "        # Retrieve and return the index of the landmark with the matching color\n",
    "        return self._goal_memory[goal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48973469-f7fe-4e2b-89e7-4a6dc74e853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListenerPolicy:\n",
    "    \"\"\"Smart listener: identifies communication channels, \n",
    "    decodes them, and navigates towards the given goal.\"\"\"\n",
    "    \n",
    "    def predict(self, observation):\n",
    "        \"\"\"\n",
    "        Policy prediction for the listener.\n",
    "        Input: \n",
    "            - observation: Current environment observation for the listener, \n",
    "              including communication and goal positions.\n",
    "        Output:\n",
    "            - Optimal action: Encoded movement towards the goal.\n",
    "        \"\"\"\n",
    "        # Extract the last 3 elements of the observation, which represent communication channels\n",
    "        com_channels = observation[-3:]\n",
    "        \n",
    "        # Default goal ID set to 0 (in case no valid communication is detected)\n",
    "        goal_id = 0\n",
    "        \n",
    "        # Identify which communication channel is active (goal identifier)\n",
    "        goal = np.where(com_channels)[0]\n",
    "        \n",
    "        # Check if any goal is communicated\n",
    "        if goal.size > 0:\n",
    "            # Extract the goal ID from the active communication channel\n",
    "            goal_id = int(goal)\n",
    "        \n",
    "        # Determine the position of the identified goal from the observation\n",
    "        goal_pos = observation[(goal_id * 2 + 2):(goal_id * 2 + 4)]\n",
    "        \n",
    "        # Decide the axis (x or y) based on which direction is further away\n",
    "        axis = np.argmax(np.abs(goal_pos))\n",
    "        \n",
    "        # If the goal position on the chosen axis is negative, move in the negative direction\n",
    "        if goal_pos[axis] < 0:\n",
    "            return axis * 2 + 1  # Encodes movement in the negative direction\n",
    "        \n",
    "        # Otherwise, move in the positive direction\n",
    "        return axis * 2 + 2  # Encodes movement in the positive direction\n",
    "\n",
    "\n",
    "def policy(observation, agent):\n",
    "    \"\"\"\n",
    "    Policy switcher based on the agent type.\n",
    "    Input:\n",
    "        - observation: The agent's observation of the environment.\n",
    "        - agent: The identifier of the current agent.\n",
    "    Output:\n",
    "        - The chosen action based on the agent's policy.\n",
    "    \"\"\"\n",
    "    # If the agent is the speaker, use the SpeakerPolicy to determine the action\n",
    "    if agent == \"speaker_0\":\n",
    "        return speaker_policy.predict(observation)\n",
    "    \n",
    "    # Otherwise, use the ListenerPolicy to determine the action\n",
    "    return listener_policy.predict(observation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a7e4af3-aa0b-41e9-9297-19db786cb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1  # Set the number of episodes for the environment simulation\n",
    "\n",
    "# Loop through each episode\n",
    "for ep in range(num_episodes):\n",
    "    env.reset()  # Reset the environment to its initial state\n",
    "\n",
    "    # Initialise the Speaker and Listener policies with their respective configurations\n",
    "    speaker_policy = SpeakerPolicy(env.env.world)  # Speaker policy based on the environment's world\n",
    "    listener_policy = ListenerPolicy()  # Listener policy to handle navigation and goal-following\n",
    "\n",
    "    # Initialise total rewards for each agent to track performance\n",
    "    total_reward = {agent: 0 for agent in env.agents}\n",
    "\n",
    "    # Iterate through each agent in the environment using agent iteration\n",
    "    for agent in env.agent_iter():\n",
    "        # Retrieve the latest observation, reward, termination, truncation, and additional info for the current agent\n",
    "        observation, reward, termination, trunc, info = env.last()\n",
    "        \n",
    "        # Accumulate the reward for the current agent\n",
    "        total_reward[agent] += reward\n",
    "\n",
    "        # Determine the action to take:\n",
    "        # If the agent's episode has terminated or truncated, no action is taken (action = None).\n",
    "        # Otherwise, the agent performs action `1` as a placeholder.\n",
    "        action = None if (termination or trunc) else 1\n",
    "        \n",
    "        # Execute the chosen action in the environment\n",
    "        env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb0f6a23-84c8-4fbd-8612-404994f1b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d1769f7-099a-442c-a7a3-28c2914ae1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "action is not in action space",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 36\u001b[0m\n\u001b[1;32m     29\u001b[0m     action \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     30\u001b[0m         speaker_policy\u001b[38;5;241m.\u001b[39mpredict(observation)\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m agent \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeaker_0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Use the speaker policy if the agent is the speaker\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m listener_policy\u001b[38;5;241m.\u001b[39mpredict(observation)  \u001b[38;5;66;03m# Use the listener policy otherwise\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Step the environment forward with the selected action\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Render the current state of the environment\u001b[39;00m\n\u001b[1;32m     39\u001b[0m img \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender()  \u001b[38;5;66;03m# Generate the environment's visual output\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/pettingzoo/utils/wrappers/order_enforcing.py:96\u001b[0m, in \u001b[0;36mOrderEnforcingWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/pettingzoo/utils/wrappers/base.py:47\u001b[0m, in \u001b[0;36mBaseWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActionType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/pettingzoo/utils/wrappers/assert_out_of_bounds.py:18\u001b[0m, in \u001b[0;36mAssertOutOfBoundsWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActionType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m---> 18\u001b[0m         action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminations[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_selection]\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncations[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_selection]\n\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_selection)\u001b[38;5;241m.\u001b[39mcontains(\n\u001b[1;32m     24\u001b[0m         action\n\u001b[1;32m     25\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction is not in action space\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "\u001b[0;31mAssertionError\u001b[0m: action is not in action space"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))  # Create a figure and axis for displaying the environment's rendering\n",
    "\n",
    "num_episodes = 1  # Set the number of episodes to simulate\n",
    "\n",
    "# Loop through each episode\n",
    "for ep in range(num_episodes):\n",
    "    env.reset()  # Reset the environment to its initial state\n",
    "\n",
    "    # Initialise the Speaker and Listener policies\n",
    "    speaker_policy = SpeakerPolicy(env.env.env.world)  # Initialise the speaker policy using the environment world\n",
    "    listener_policy = ListenerPolicy()  # Initialise the listener policy for navigation and goal decoding\n",
    "\n",
    "    # Initialise a dictionary to track total rewards for each agent\n",
    "    total_reward = {agent: 0 for agent in env.agents}\n",
    "\n",
    "    # Iterate through each agent in the environment using agent iteration\n",
    "    for agent in env.agent_iter():\n",
    "        # Retrieve the latest observation, reward, termination, truncation, and additional info for the current agent\n",
    "        observation, reward, termination, trunc, info = env.last()\n",
    "        \n",
    "        # Accumulate the total reward for the current agent\n",
    "        total_reward[agent] += reward\n",
    "\n",
    "        # Determine the action to perform based on the agent's state\n",
    "        if termination or trunc:\n",
    "            action = None  # No action is taken if the agent is terminated or truncated\n",
    "        else:\n",
    "            # Use the appropriate policy (speaker or listener) to determine the action\n",
    "            action = (\n",
    "                speaker_policy.predict(observation)\n",
    "                if agent == \"speaker_0\"  # Use the speaker policy if the agent is the speaker\n",
    "                else listener_policy.predict(observation)  # Use the listener policy otherwise\n",
    "            )\n",
    "\n",
    "        # Step the environment forward with the selected action\n",
    "        env.step(action)\n",
    "\n",
    "        # Render the current state of the environment\n",
    "        img = env.render()  # Generate the environment's visual output\n",
    "        plt.imshow(img)  # Display the rendered image using matplotlib\n",
    "\n",
    "        # Optional: Update the display in real-time\n",
    "        # Uncomment plt.show() if running outside of a Jupyter Notebook\n",
    "        # plt.show()\n",
    "        clear_output(wait=True)  # Clear the previous frame to display the new one\n",
    "        plt.pause(0.1)  # Pause for a short duration to simulate animation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93412e80-c2bd-47ef-86cc-9cabafcc9384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
