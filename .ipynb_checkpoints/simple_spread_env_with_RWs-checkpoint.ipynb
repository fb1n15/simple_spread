{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a0af50-8087-412c-9a9f-1dc0f33d3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.mpe import simple_spread_v3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a4c471-5011-40f9-a3e5-d5beb439b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of agents in the environment\n",
    "num_agents = 3\n",
    "\n",
    "# Initialize the 'simple_spread_v2' environment with specified parameters\n",
    "env = simple_spread_v3.env(\n",
    "    N=num_agents,                 # Number of agents and landmarks in the environment\n",
    "    max_cycles=25,                # Maximum number of steps (cycles) per episode\n",
    "    local_ratio=0.5,              # Weight applied to local versus global rewards\n",
    "    continuous_actions=False,     # Use discrete action space\n",
    "    render_mode='rgb_array',      # Set the rendering mode to return RGB frames\n",
    "    # render_mode = 'human'    # display the environment's state in a window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480ef51e-db3a-4a0b-8b08-151eaedb74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c13540-188c-4ab0-ab66-a8136ece2bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_0', 'agent_1', 'agent_2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96bfa165-fdf3-4731-9d25-2ba81c6a8cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_0 Box(-inf, inf, (18,), float32)\n",
      "agent_1 Box(-inf, inf, (18,), float32)\n",
      "agent_2 Box(-inf, inf, (18,), float32)\n"
     ]
    }
   ],
   "source": [
    "for agent in env.agents:\n",
    "    print(agent, env.observation_space(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0a466-1d00-48d0-a72a-911595b11f32",
   "metadata": {},
   "source": [
    "## Agents' Observation Space\n",
    "In the `simple_spread_v2` environment from PettingZoo's Multi-Agent Particle Environments (MPE), each agent's observation is represented by a one-dimensional NumPy array with 18 elements, corresponding to the `Box(-inf, inf, (18,), float32)` observation space.\n",
    "\n",
    "This observation vector comprises the following components:\n",
    "\n",
    "1. **Agent's Own Velocity (`self_vel`)**:\n",
    "   - **Dimensions**: 2\n",
    "   - **Description**: The agent's current velocity in the 2D plane, represented by its x and y components.\n",
    "\n",
    "2. **Agent's Own Position (`self_pos`)**:\n",
    "   - **Dimensions**: 2\n",
    "   - **Description**: The agent's current position coordinates in the environment.\n",
    "\n",
    "3. **Relative Positions of Landmarks (`landmark_rel_positions`)**:\n",
    "   - **Dimensions**: 2 per landmark\n",
    "   - **Description**: The position of each landmark relative to the agent's current position. With 3 landmarks, this results in 6 dimensions.\n",
    "\n",
    "4. **Relative Positions of Other Agents (`other_agent_rel_positions`)**:\n",
    "   - **Dimensions**: 2 per other agent\n",
    "   - **Description**: The positions of other agents relative to the current agent's position. With 2 other agents, this accounts for 4 dimensions.\n",
    "\n",
    "5. **Communication from Other Agents (`communication`)**:\n",
    "   - **Dimensions**: 2\n",
    "   - **Description**: Communication signals received from other agents. In this environment, agents are silent, so this component is typically zeroed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595eea06-e656-4d15-a03c-9e02e8d03254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_0 Discrete(5)\n",
      "agent_1 Discrete(5)\n",
      "agent_2 Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "for agent in env.agents:\n",
    "    print(agent, env.action_space(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0e8cf-3421-4fce-a1c5-8d9bd9e7abf0",
   "metadata": {},
   "source": [
    "## Action space\n",
    "This indicates that the agent can choose from 5 distinct actions, typically corresponding to:\n",
    "\n",
    "No Action: The agent remains stationary.\n",
    "Move Left: The agent moves to the left.\n",
    "Move Right: The agent moves to the right.\n",
    "Move Down: The agent moves downward.\n",
    "Move Up: The agent moves upward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b17e95-ea6a-4ce7-bb82-0c624483d7cf",
   "metadata": {},
   "source": [
    "# Use stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21665d63-4781-4f2d-8cbf-bcb2fb90ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from pettingzoo.mpe import simple_spread_v2\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import PPO\n",
    "from supersuit import (\n",
    "    pad_action_space_v0,\n",
    "    pad_observations_v0,\n",
    "    pettingzoo_env_to_vec_env_v1,\n",
    "    concat_vec_envs_v1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c11c92-e766-4005-a99c-5382f97489f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "num_agents = 3\n",
    "env = simple_spread_v3.parallel_env(\n",
    "    N=num_agents, max_cycles=25, local_ratio=0.5, continuous_actions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478ff373-fc01-4c7f-a2b5-abfcbe18647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad action and observation spaces to handle varying spaces among agents\n",
    "env = pad_observations_v0(env)\n",
    "env = pad_action_space_v0(env)\n",
    "\n",
    "# Convert the PettingZoo environment to a vectorized environment\n",
    "env = pettingzoo_env_to_vec_env_v1(env)\n",
    "\n",
    "# Concatenate vectorized environments for parallel execution\n",
    "num_envs = 4  # Number of parallel environments\n",
    "env = concat_vec_envs_v1(env, num_envs, num_cpus=1, base_class='stable_baselines3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4913b18-a1c6-45f3-b296-2b55779383f9",
   "metadata": {},
   "source": [
    "## Vectorized environment's Key Features and Benefits\n",
    "### Parallel Execution:\n",
    "Vectorized environments enable the execution of multiple environments in parallel. This can significantly speed up the data sampling process, especially when using multiple CPU cores or GPUs.\n",
    "### Batched Actions and Observations:\n",
    "Instead of passing a single action and receiving a single observation and reward, vectorized environments handle batches of actions, observations, and rewards. This means that the agent can take multiple actions and receive multiple observations and rewards in each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b4cfca-a29c-4916-b851-1bda1ea445c5",
   "metadata": {},
   "source": [
    "## Train each agent independently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f796a337-5dca-4b1f-9ada-b3694152864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Using cpu device\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the models for each agent (each agent has an independent policy)\n",
    "models = []\n",
    "\n",
    "# Loop over the number of agents to create and configure a PPO model for each\n",
    "for agent_id in range(num_agents):\n",
    "    # Initialize a PPO model with the following parameters:\n",
    "    # - 'MlpPolicy': Indicates the use of a multi-layer perceptron policy network\n",
    "    # - env: The environment in which the agent will be trained\n",
    "    # - verbose=3: Sets the verbosity level to 3 for detailed logging during training\n",
    "    # - device=\"cpu\": Specifies that the model should be trained on the CPU\n",
    "    model = PPO('MlpPolicy', env,\n",
    "                n_steps=1024,  # the number of steps the agent collects in each environment before performing a policy update\n",
    "                verbose=3, device=\"cpu\",\n",
    "               # tensorboard_log=\"./ppo_logs/\"\n",
    "               )\n",
    "    \n",
    "    # Append the initialized model to the models list\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a7822-612f-40ad-8f8f-af9018338cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8330  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5147        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006066808 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | 0.00142     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4563        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006074939 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | 0.0633      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4322         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061598434 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.07        |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4183         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061477125 |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.07        |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "Iteration 1, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8261  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5120         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061112694 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | -0.00426     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4523       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00637635 |\n",
      "|    clip_fraction        | 0.0639     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.09      |\n",
      "|    explained_variance   | 0.034      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00557   |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 30.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4293        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005839625 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | 0.075       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4156        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006754219 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.05       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "Iteration 1, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8209  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5123        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006340344 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | -0.00154    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4558        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006057542 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.06       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4317        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006113235 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.04       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4184         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068302467 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.02        |\n",
      "|    explained_variance   | 0.078        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "Iteration 2, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8376  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5116        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006904468 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.02       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3426         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068647577 |\n",
      "|    clip_fraction        | 0.0696       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7           |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3498         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065232865 |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.97        |\n",
      "|    explained_variance   | 0.104        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3536         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070207226 |\n",
      "|    clip_fraction        | 0.0756       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.97        |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "Iteration 2, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8186  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5093        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006355436 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.99       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4538         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067038476 |\n",
      "|    clip_fraction        | 0.0811       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.98        |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4305        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006477885 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.99       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4177         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064034997 |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7           |\n",
      "|    explained_variance   | 0.13         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "Iteration 2, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8316  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5142       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00632636 |\n",
      "|    clip_fraction        | 0.0708     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7         |\n",
      "|    explained_variance   | 0.146      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.3       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00531   |\n",
      "|    std                  | 0.981      |\n",
      "|    value_loss           | 37.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3443        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006250405 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.99       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2944        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006547651 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.98       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3072         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067848396 |\n",
      "|    clip_fraction        | 0.0681       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.96        |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "Iteration 3, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8304  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5108         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069529787 |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.95        |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4530        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006446602 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4298         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075983093 |\n",
      "|    clip_fraction        | 0.083        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.9         |\n",
      "|    explained_variance   | 0.236        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4172         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072617293 |\n",
      "|    clip_fraction        | 0.0789       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.9         |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "Iteration 3, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8306  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5134         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074912086 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.97        |\n",
      "|    explained_variance   | 0.198        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4553         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071335547 |\n",
      "|    clip_fraction        | 0.0742       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.95        |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4301        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006797264 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.92       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4170        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007582824 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.89       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "Iteration 3, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8355  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5137        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006422296 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.93       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4564        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006860403 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4324         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069121174 |\n",
      "|    clip_fraction        | 0.0757       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.9         |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4191        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007439483 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "Iteration 4, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8434  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5149       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00795725 |\n",
      "|    clip_fraction        | 0.0824     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.84      |\n",
      "|    explained_variance   | 0.307      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.41       |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00686   |\n",
      "|    std                  | 0.951      |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3421         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074184244 |\n",
      "|    clip_fraction        | 0.085        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.81        |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 22.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3491       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00725996 |\n",
      "|    clip_fraction        | 0.0783     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.8       |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.54       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.00608   |\n",
      "|    std                  | 0.941      |\n",
      "|    value_loss           | 22.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3534         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073334067 |\n",
      "|    clip_fraction        | 0.0837       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.78        |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.8          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "Iteration 4, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8344  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5150         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076598986 |\n",
      "|    clip_fraction        | 0.0853       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.86        |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.93         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4569        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007788958 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4320        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007869341 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.79       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4189        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007900243 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.77       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.48        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    std                  | 0.936       |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "Iteration 4, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8414  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5158        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007431552 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.82       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4570        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007560409 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.8        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4322         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074417028 |\n",
      "|    clip_fraction        | 0.084        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.78        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.07         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4187        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007785613 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.77       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "Iteration 5, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8346  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5149        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770518 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.73       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.51        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    std                  | 0.93        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4553        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007836748 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.73       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.72        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    std                  | 0.93        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4302        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008575593 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.71       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.77        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4172        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008170004 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.72       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "Iteration 5, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8328  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5151         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073453537 |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.74        |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.63         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    std                  | 0.928        |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4561        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007788912 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.73       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.74        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4320        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008076654 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.71       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.8         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4188         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076296697 |\n",
      "|    clip_fraction        | 0.0901       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.7         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.47         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    std                  | 0.924        |\n",
      "|    value_loss           | 14.8         |\n",
      "------------------------------------------\n",
      "Iteration 5, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8265  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5138        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008068797 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.71       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4553        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007542185 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.7        |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4308        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008253072 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.68       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.13        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4175        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031883 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.65       |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "Iteration 6, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8237  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5112         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075091184 |\n",
      "|    clip_fraction        | 0.0863       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.7         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.4          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    std                  | 0.924        |\n",
      "|    value_loss           | 13.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3412         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086547015 |\n",
      "|    clip_fraction        | 0.0957       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.69        |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.18         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    std                  | 0.921        |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3486        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007964964 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.67       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3532        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008005883 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.05        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "Iteration 6, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8362  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5147        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008530732 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.67       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.61        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4564        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007997106 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.65       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.63        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    std                  | 0.916       |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4317        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008505776 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.59        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4181         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075775967 |\n",
      "|    clip_fraction        | 0.084        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.61        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.09         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    std                  | 0.907        |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "Iteration 6, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8307  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5142        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008594815 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.6        |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.48        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 0.904       |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4550        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008012508 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.57       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4306         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083333785 |\n",
      "|    clip_fraction        | 0.0953       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.54        |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 19.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4171        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008620214 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.51       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.7         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    std                  | 0.89        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "Iteration 7, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8178  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5097        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009599736 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.11        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4519        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711958 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.61       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4287       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00909681 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.58      |\n",
      "|    explained_variance   | 0.532      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.89       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00714   |\n",
      "|    std                  | 0.903      |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4153        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009828747 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.54       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "Iteration 7, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8196  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5114         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090293605 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.55        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.15         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4544         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077860444 |\n",
      "|    clip_fraction        | 0.0942       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.54        |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.85         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    std                  | 0.895        |\n",
      "|    value_loss           | 9.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4305         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077138394 |\n",
      "|    clip_fraction        | 0.0843       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.53        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.17         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    std                  | 0.893        |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4175        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009677877 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.54       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 9.88        |\n",
      "-----------------------------------------\n",
      "Iteration 7, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8385  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5151        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009046062 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.47       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.31        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4564        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009745732 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.94        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 0.877       |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4321        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009562069 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.43       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.33        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4186        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007585278 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.43       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "Iteration 8, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8332  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5144        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009265964 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.49       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.37        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    std                  | 0.885       |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4568        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010017407 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.09        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 10.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4327        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009716059 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    std                  | 0.876       |\n",
      "|    value_loss           | 9.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3543        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010096219 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.42       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.3         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "Iteration 8, Training agent 2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8331  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3301        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008854103 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.46       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.66        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    std                  | 0.881       |\n",
      "|    value_loss           | 9.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2746        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009477572 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.39        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    std                  | 0.877       |\n",
      "|    value_loss           | 9.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2941        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009912035 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.43       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 9.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3072        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009921365 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.57        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    std                  | 0.87        |\n",
      "|    value_loss           | 8.07        |\n",
      "-----------------------------------------\n",
      "Iteration 8, Training agent 3\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8404  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5165        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009345734 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.94        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4579         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089312205 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.35        |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.05         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    std                  | 0.862        |\n",
      "|    value_loss           | 13.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4338        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008570315 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.36       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.96        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4201        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010100101 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.32       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.27        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "Iteration 9, Training agent 1\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8427  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 1     |\n",
      "|    total_timesteps | 12288 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5168        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010052483 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.42       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.52        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4572        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009628729 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4326        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009426252 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.38       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.3         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Total number of iterations\n",
    "total_iterations = 100\n",
    "\n",
    "# Number of steps each agent learns per iteration\n",
    "steps_per_agent = 50000\n",
    "\n",
    "# In Stable Baselines3’s implementation of Proximal Policy Optimization (PPO), \n",
    "# the model.learn() function continues training the existing policy rather than initializing a new one with each call.\n",
    "for iteration in range(total_iterations):\n",
    "    for agent_id, model in enumerate(models):\n",
    "        print(f\"Iteration {iteration + 1}, Training agent {agent_id + 1}\")\n",
    "        model.learn(total_timesteps=steps_per_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46645c8a-13b5-488b-8f50-bd880fe74b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Stopping the notebook execution.\")\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c87f5a39-8195-44f8-9f4f-ef4d606bb8f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=3, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb2fc463-e6a0-452e-b02f-e723d488573c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 8395  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 2     |\n",
      "|    total_timesteps | 24576 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3304        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005600501 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | -0.00222    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.63        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2747         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052253716 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.06        |\n",
      "|    explained_variance   | 0.048        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2532         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054495633 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.03        |\n",
      "|    explained_variance   | 0.069        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2702         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055209496 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.01        |\n",
      "|    explained_variance   | 0.09         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2564        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005628578 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | 0.079       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2472        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006063066 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.0618      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2580        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005529359 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.92       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:336\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:278\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    210\u001b[0m     state_steps: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     adam(\n\u001b[1;32m    224\u001b[0m         params_with_grad,\n\u001b[1;32m    225\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/learn-stable-baseline3-wCRf4qmO-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:129\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    127\u001b[0m has_complex \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_complex(p)\n\u001b[1;32m    128\u001b[0m params_with_grad\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam does not support sparse gradients, please consider SparseAdam instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    133\u001b[0m grads\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mgrad)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d07ad3-4d8b-4340-b00d-0aa81ba5cf42",
   "metadata": {},
   "source": [
    "### **How to Interpret Training Output**\n",
    "\n",
    "1. **Monitor Rewards (`ep_rew_mean`):**\n",
    "   - A consistently rising mean reward (`ep_rew_mean`) is a good indicator that the agent is learning to perform better in the environment.\n",
    "   - If the reward plateaus or drops significantly, this could suggest that the agent has reached a suboptimal solution or is struggling to learn.\n",
    "\n",
    "2. **Look at Episode Length (`ep_len_mean`):**\n",
    "   - If your environment terminates episodes upon failure, a longer `ep_len_mean` indicates fewer failures.\n",
    "   - In environments with fixed episode lengths, this value might remain constant.\n",
    "\n",
    "3. **Entropy (`entropy_loss`):**\n",
    "   - Early in training, higher entropy values are expected because the agent is still exploring.\n",
    "   - Over time, entropy should decrease as the agent settles on an optimal policy.\n",
    "\n",
    "4. **Loss Metrics (`value_loss`, `policy_loss`):**\n",
    "   - These should gradually decrease but not hit zero, as they represent the errors the model is correcting.\n",
    "   - Sudden spikes in these values can indicate instability, such as an inappropriate learning rate or poor exploration.\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Issues Observed in Training Output**\n",
    "- **Low FPS:** Indicates inefficiencies in the environment or code.\n",
    "- **Flat Rewards (`ep_rew_mean`):** Indicates that the agent is not learning. Try adjusting hyperparameters like the learning rate, exploration strategy, or reward structure.\n",
    "- **Diverging Loss Values:** A sign of instability. Ensure that your reward function is properly scaled and check for bugs in the environment.\n",
    "\n",
    "---\n",
    "\n",
    "By analysing these outputs, you can fine-tune your training process to achieve better results. Let me know if you want help debugging a specific output!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf71703-d5e4-471b-859a-a0fd37eb6a1a",
   "metadata": {},
   "source": [
    "## **Additional Considerations:**\n",
    "\n",
    "- **Parameter Sharing:** The above setup employs parameter sharing, where a single policy network is shared among all agents. This approach is commonly used in multi-agent reinforcement learning to reduce computational complexity and improve coordination among agents.\n",
    "\n",
    "- **Environment-Specific Adjustments:** Depending on the characteristics of the `simple_spread_v3` environment, you might need to apply additional wrappers or adjustments. For instance, if the environment provides visual observations, you may need to include wrappers for frame stacking or resizing.\n",
    "\n",
    "- **Compatibility Issues:** Be aware of potential compatibility issues between different versions of the libraries. It's advisable to consult the official documentation and release notes for PettingZoo, SuperSuit, and Stable-Baselines3 to ensure seamless integration.\n",
    "\n",
    "By following these steps, you can effectively wrap the `simple_spread_v3` environment using SuperSuit, making it compatible with Stable-Baselines3 for training multi-agent reinforcement learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b88477-0bf7-4751-9f2b-090ec859b242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
